{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a model from scratch ##\n",
    "\n",
    "To train your own model from scratch, the ` Trainer ` class provides a simple implementation. Simply define your a custom dataset and a ` Trainer ` object, and call the ` Trainer ` 's ` fit() ` method."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing a custom dataset ##\n",
    "\n",
    "When creating a custom time series dataset class for use with Cents, the class must inherit from the provided `TimeSeriesDataset` base class. The `TimeSeriesDataset` class provides a robust and modular framework for handling wide-format time series data. Custom implementations only need to assign a name to `self.name` and implement the `_preprocess_data` method, which is an abstract method in the base class. This method should ensure that the data is available in a clean wide-format data frame, that has the structure outlined below.\n",
    "\n",
    "### Responsibilities of `_preprocess_data`\n",
    "\n",
    "- Preprocess raw input data into a DataFrame that satisfies the expected structure.\n",
    "- Ensure time series columns contain arrays of the correct sequence length (`seq_len`).\n",
    "- Add any additional columns, such as entity identifiers or context variables.\n",
    "\n",
    "### Benefits of the Base Class\n",
    "\n",
    "- **Normalization and Scaling:** Automatically handles standardization and min-max scaling.\n",
    "- **context Variables:** Provides support for encoding and managing context variables.\n",
    "- **Time Series Merging and Splitting:** Facilitates operations to merge multiple time series columns into a single multidimensional array and split them back when needed.\n",
    "- **Data Transformation:** Includes functions for inverse transformations to revert normalized data to its original scale.\n",
    "\n",
    "---\n",
    "\n",
    "### Expected Input DataFrame Structure\n",
    "\n",
    "The input to the `TimeSeriesDataset` class must adhere to the following structure:\n",
    "\n",
    "| **Column Name**       | **Description**                                                                                     |\n",
    "|------------------------|-----------------------------------------------------------------------------------------------------|\n",
    "| `timeseries_col1`      | A column containing arrays of length `seq_len` (after preprocessing) representing the first dimension of the time series. |\n",
    "| `timeseries_col2`      | A column containing arrays of length `seq_len` (after preprocessing) representing the second dimension of the time series.|\n",
    "| `entity_column`        | A column containing unique identifiers for each entity (e.g., user, household, or device ID).       |\n",
    "| `context_var1`    | An (optional) static or numeric context variable (e.g., categorical or continuous feature).                |\n",
    "| `context_var2`    | Further (optional) static or numeric context variables.                                                    |\n",
    "\n",
    "- The `time_series_column_names` parameter specifies which columns are part of the time series.\n",
    "- The `entity_column_name` parameter identifies the column containing unique entity IDs.\n",
    "- The `context_var_column_names` parameter defines additional context variables.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from cents.datasets.timeseries_dataset import TimeSeriesDataset\n",
    "from cents.trainer import Trainer\n",
    "\n",
    "class CustomTimeSeriesDataset(TimeSeriesDataset):\n",
    "    \"\"\"\n",
    "    A custom TimeSeriesDataset implementation for handling toy data.\n",
    "\n",
    "    Input data structure:\n",
    "    - time_series_col1, time_series_col2: Time series data with arrays of length seq_len.\n",
    "    - entity_id: Unique identifier for each entity.\n",
    "    - static_context: Categorical or numeric context variable.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        data: pd.DataFrame,\n",
    "        seq_len: int = 16,\n",
    "        normalize: bool = False,\n",
    "        scale: bool = False,\n",
    "    ):\n",
    "        time_series_column_names = [\"time_series_col1\", \"time_series_col2\"]\n",
    "        context_var_column_names = [\"context_var\"]\n",
    "\n",
    "        super().__init__(\n",
    "            data=data,\n",
    "            time_series_column_names=time_series_column_names,\n",
    "            context_var_column_names=context_var_column_names,\n",
    "            seq_len=seq_len,\n",
    "            normalize=normalize,\n",
    "            scale=scale,\n",
    "\n",
    "        )\n",
    "\n",
    "    def _preprocess_data(self, data: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Preprocesses the raw input data to ensure it conforms to the expected format.\n",
    "\n",
    "        - Ensures time series columns contain arrays of length seq_len.\n",
    "        - Ensures all required columns are present.\n",
    "\n",
    "        Args:\n",
    "            data (pd.DataFrame): The raw input data.\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: The preprocessed data.\n",
    "        \"\"\"\n",
    "        required_columns = [\"time_series_col1\", \"time_series_col2\", \"context_var\"]\n",
    "        for col in required_columns:\n",
    "            if col not in data.columns:\n",
    "                raise ValueError(f\"Missing required column: {col}\")\n",
    "\n",
    "        for col in [\"time_series_col1\", \"time_series_col2\"]:\n",
    "            data[col] = data[col].apply(\n",
    "                lambda x: np.array(x).reshape(-1, 1) if isinstance(x, list) else x\n",
    "            )\n",
    "            data[col] = data[col].apply(\n",
    "                lambda x: np.array(x) if isinstance(x, np.ndarray) else ValueError(f\"Invalid data in {col}\")\n",
    "            )\n",
    "        for col in [\"time_series_col1\", \"time_series_col2\"]:\n",
    "            data[col] = data[col].apply(\n",
    "                lambda x: x[:self.seq_len] if len(x) >= self.seq_len else ValueError(f\"Sequence too short in {col}\")\n",
    "            )\n",
    "        return data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have defined our dataset class, let's create some artificial timeseries columns and context variables which will comprise our dataset. Note that because we passed normalize=False, we are not using a parametric normalizer. If we set normalize=True, we will train a parametric normalizer with the default training config."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>context_var</th>\n",
       "      <th>timeseries</th>\n",
       "      <th>is_frequency_rare</th>\n",
       "      <th>cluster</th>\n",
       "      <th>is_pattern_rare</th>\n",
       "      <th>is_rare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>[[0.846557892139889, 0.675851372726446], [0.06...</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[[0.3243788307509139, 0.5343991059414336], [0....</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>[[0.9449073249670529, 0.8339985335984342], [0....</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>[[0.7986038440807655, 0.5108029540184494], [0....</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>[[0.3616056430625689, 0.7913010437773548], [0....</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>95</td>\n",
       "      <td>2</td>\n",
       "      <td>[[0.12553835225328158, 0.008270644063553378], ...</td>\n",
       "      <td>False</td>\n",
       "      <td>9</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>96</td>\n",
       "      <td>1</td>\n",
       "      <td>[[0.2647745296948498, 0.20852458676197916], [0...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>97</td>\n",
       "      <td>0</td>\n",
       "      <td>[[0.8153611215783628, 0.7881865609193799], [0....</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>98</td>\n",
       "      <td>1</td>\n",
       "      <td>[[0.9726672872762161, 0.7746102461251492], [0....</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "      <td>[[0.200131107946247, 0.5805481317170115], [0.1...</td>\n",
       "      <td>False</td>\n",
       "      <td>8</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    index  context_var                                         timeseries  \\\n",
       "0       0            2  [[0.846557892139889, 0.675851372726446], [0.06...   \n",
       "1       1            0  [[0.3243788307509139, 0.5343991059414336], [0....   \n",
       "2       2            0  [[0.9449073249670529, 0.8339985335984342], [0....   \n",
       "3       3            2  [[0.7986038440807655, 0.5108029540184494], [0....   \n",
       "4       4            0  [[0.3616056430625689, 0.7913010437773548], [0....   \n",
       "..    ...          ...                                                ...   \n",
       "95     95            2  [[0.12553835225328158, 0.008270644063553378], ...   \n",
       "96     96            1  [[0.2647745296948498, 0.20852458676197916], [0...   \n",
       "97     97            0  [[0.8153611215783628, 0.7881865609193799], [0....   \n",
       "98     98            1  [[0.9726672872762161, 0.7746102461251492], [0....   \n",
       "99     99            1  [[0.200131107946247, 0.5805481317170115], [0.1...   \n",
       "\n",
       "    is_frequency_rare  cluster  is_pattern_rare  is_rare  \n",
       "0               False        2             True    False  \n",
       "1                True        9             True     True  \n",
       "2                True        1             True     True  \n",
       "3               False        3            False    False  \n",
       "4                True        2             True     True  \n",
       "..                ...      ...              ...      ...  \n",
       "95              False        9             True    False  \n",
       "96              False        0             True    False  \n",
       "97               True        3            False    False  \n",
       "98              False        4             True    False  \n",
       "99              False        8             True    False  \n",
       "\n",
       "[100 rows x 7 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.DataFrame({\n",
    "        \"time_series_col1\": [np.random.rand(16) for _ in range(100)],\n",
    "        \"time_series_col2\": [np.random.rand(16) for _ in range(100)],\n",
    "        \"context_var\": np.random.choice([\"a\", \"b\", \"c\"], size=100).tolist(),\n",
    "    })\n",
    "\n",
    "custom_dataset = CustomTimeSeriesDataset(data)\n",
    "custom_dataset.data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now create a `Trainer` object by passing the name of the desired model and the dataset object. To start training, simply call `Trainer.fit()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 2 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=2)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | context_module | ContextModule     | 4.3 K  | train\n",
      "1 | generator      | Generator         | 309 K  | train\n",
      "2 | discriminator  | Discriminator     | 167 K  | train\n",
      "3 | adv_loss       | BCEWithLogitsLoss | 0      | train\n",
      "4 | aux_loss       | CrossEntropyLoss  | 0      | train\n",
      "-------------------------------------------------------------\n",
      "477 K     Trainable params\n",
      "0         Non-trainable params\n",
      "477 K     Total params\n",
      "1.909     Total estimated model params size (MB)\n",
      "37        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90078f1a18c7436ca07349efba309690",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<cents.trainer.Trainer at 0x7f2b3c0a63a0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = Trainer(model_name=\"acgan\", dataset=custom_dataset, overrides=[\"trainer.max_epochs=5\", \"trainer.strategy=auto\"])\n",
    "trainer.fit()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once training is complete, we can create a data generator object that has access to the trained model and dataset information. To generate data, there is no need to load in a trained model. Simply define the context variables, and call the `DataGenerator` 's `generate()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_generator = trainer.get_data_generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context_var</th>\n",
       "      <th>timeseries</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>[[0.35216045, 0.524036], [0.40860957, 0.526294...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>[[0.39892834, 0.51737106], [0.41330722, 0.4979...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[[0.36629742, 0.54354775], [0.43322757, 0.5283...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>[[0.36517504, 0.48562878], [0.4277414, 0.53091...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>[[0.33892456, 0.5168193], [0.36130148, 0.55954...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>2</td>\n",
       "      <td>[[0.36958477, 0.53076947], [0.41364932, 0.5436...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>2</td>\n",
       "      <td>[[0.36272144, 0.5096975], [0.3763022, 0.571060...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>2</td>\n",
       "      <td>[[0.36221316, 0.50699925], [0.40216798, 0.4204...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>2</td>\n",
       "      <td>[[0.3906406, 0.5122451], [0.39646956, 0.502664...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>2</td>\n",
       "      <td>[[0.36968455, 0.524881], [0.40184453, 0.504652...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    context_var                                         timeseries\n",
       "0             2  [[0.35216045, 0.524036], [0.40860957, 0.526294...\n",
       "1             2  [[0.39892834, 0.51737106], [0.41330722, 0.4979...\n",
       "2             2  [[0.36629742, 0.54354775], [0.43322757, 0.5283...\n",
       "3             2  [[0.36517504, 0.48562878], [0.4277414, 0.53091...\n",
       "4             2  [[0.33892456, 0.5168193], [0.36130148, 0.55954...\n",
       "..          ...                                                ...\n",
       "95            2  [[0.36958477, 0.53076947], [0.41364932, 0.5436...\n",
       "96            2  [[0.36272144, 0.5096975], [0.3763022, 0.571060...\n",
       "97            2  [[0.36221316, 0.50699925], [0.40216798, 0.4204...\n",
       "98            2  [[0.3906406, 0.5122451], [0.39646956, 0.502664...\n",
       "99            2  [[0.36968455, 0.524881], [0.40184453, 0.504652...\n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_generator.set_context(context_var=2)\n",
    "generated_df = data_generator.generate(n=100)\n",
    "generated_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation\n",
    "\n",
    "The `Evaluator` class provides functionality to assess the quality of generated data compared to the original training data. It computes various metrics including:\n",
    "\n",
    "- Distribution similarity between real and generated data\n",
    "- Utility metrics\n",
    "- Context-FID\n",
    "\n",
    "To evaluate the trained model, we can use the `evaluate()` method of the `Trainer`. This method accepts:\n",
    "\n",
    "- A dataset to evaluate against (typically the training dataset)\n",
    "- Optional evaluation configuration parameters\n",
    "\n",
    "The evaluation results provide insights into how well the model captures the underlying data patterns and maintains the relationship with context variables.\n",
    "\n",
    "Let's run an evaluation on our trained model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CENTS] Using device: cuda for evaluation\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1aef7d72520453f96a38bd0eb789375",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[Cents] Training Discriminative Score Model:   0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b467cc83a90a463c8f907160199d1587",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[Cents] Training Predictive Score Model:   0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8115b64c5504406b06d4f3a3893f6f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[Cents] Training Discriminative Score Model:   0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "108ac9718aec4f1eaff70ff6eff74736",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[Cents] Training Predictive Score Model:   0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = trainer.evaluate()\n",
    "metadata = results[\"metadata\"]\n",
    "metrics = results[\"metrics\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'DTW': {'mean': np.float64(1.4476364766831096),\n",
       "  'std': np.float64(0.15302953610924613)},\n",
       " 'MMD': {'mean': np.float64(0.022156818688420555),\n",
       "  'std': np.float64(0.015161203706493065)},\n",
       " 'Context_FID': np.float64(4.60251026124625),\n",
       " 'Disc_Score': np.float64(0.5),\n",
       " 'Pred_Score': 0.25806143090128897,\n",
       " 'rare_subset': {'DTW': {'mean': np.float64(1.4136056858742925),\n",
       "   'std': np.float64(0.18925874125581987)},\n",
       "  'MMD': {'mean': np.float64(0.020573098136937147),\n",
       "   'std': np.float64(0.013526630793298716)},\n",
       "  'Context_FID': np.float64(4.420796978859233),\n",
       "  'Disc_Score': np.float64(0.5),\n",
       "  'Pred_Score': 0.25751564943272137},\n",
       " 'disentanglement': {'MIG': {'mean': 0.0, 'context_var': np.float64(0.0)},\n",
       "  'SAP': {'mean': 0.018952240377676066,\n",
       "   'context_var': np.float64(0.018952240377676066)}}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
