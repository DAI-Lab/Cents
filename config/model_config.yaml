seq_len: 96 # should not be changed for the current datasets
input_dim: 2 # or 1 depending on user, but is dynamically set
noise_dim: 256
cond_emb_dim: 256
shuffle: True

conditioning_vars: # for each desired conditioning variable, add the name and number of categories
  month: 12
  weekday: 7
  building_type: 3
  solar: 2
  car1: 2
  city: 7
  state: 3

diffcharge:
  batch_size: 64
  n_epochs: 1
  init_lr: 3e-5
  network: cnn # attention
  guidance_scale: 1.2
  hidden_dim: 256
  cond_emb_dim: 32
  nhead: 8
  beta_start: 1e-4
  beta_end: 0.02
  n_steps: 1000
  schedule: linear # quadratic, cosine

diffusion_ts:
  batch_size: 64
  n_epochs: 1000
  n_steps: 1000
  base_lr: 1e-4
  n_layer_enc: 4
  n_layer_dec: 5
  d_model: 128
  cond_emb_dim: 128
  sampling_timesteps: null
  loss_type: l1 #l2
  beta_schedule: cosine #linear
  n_heads: 4
  mlp_hidden_times: 4
  eta: 0.0
  attn_pd: 0.0
  resid_pd: 0.0
  kernel_size: null
  padding_size: null
  use_ff: true
  reg_weight: null
  results_folder: ./Checkpoints_syn
  gradient_accumulate_every: 2
  save_cycle: 1000
  ema_decay: 0.99
  ema_update_interval: 10
  lr_scheduler_params:
    factor: 0.5
    patience: 200
    min_lr: 1.0e-5
    threshold: 1.0e-1
    threshold_mode: rel
    verbose: false

acgan:
  batch_size: 16
  n_epochs: 1
  validate: false # add validation during training
  lr_gen: 2e-4
  lr_discr: 1e-4
